{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP with DeepSeek-R1 Tutorial\n",
    "\n",
    "This notebook tutorial showcases a step-by-step guide on how to implement DeepSeek-R1 connected to tools in MCP servers, using LangChain's MCP Adapters library (here: https://github.com/langchain-ai/langchain-mcp-adapters).\n",
    "\n",
    "I am using MCP servers from an MPC server registry/depository called MCP Server Cloud (here: https://mcpserver.cloud/, or their GitHub repo here: https://github.com/modelcontextprotocol).\n",
    "\n",
    "I will be connecting DeepSeek-R1 to 2 MCP servers, with 1 tool in each MCP server. Namely, I will be using the Brave Search MCP Server (here: https://mcpserver.cloud/server/server-brave-search) and the AccuWeather MCP Server (here: https://mcpserver.cloud/server/mcp-weather-server).\n",
    "\n",
    "To use the Brave Search MCP Server and the AccuWeather MCP Server, you will need to create a Brave Browser API key (here: https://brave.com/search/api/) and an AccuWeather API key (here: https://developer.accuweather.com/getting-started), respectively. They are both free and it's fairly straight forward to do this (but note creating a Brave Browser API key require a credit card even for the free subscription). Just ask any AI for the step-by-step guide to do this.\n",
    "\n",
    "Once you have your Brave Browser and AccuWeather API keys, save them in a .env file, along with an OpenRouter API key (for this notebook tutorial I will be using DeepSeek-R1 hosted on OpenRouter). This .env file is saved in the same folder as where this Jupyter Notebook will be saved.\n",
    "\n",
    "Now that we have all the above setup, let's get into the more technical part of this notebook tutorial. How LangChain's MCP Adapters library works is it convert tools in MCP servers into LangChain tools, so then these LangChain tools can be used within the LangChain/LangGraph framework. Yes, it's as simple as that!\n",
    "\n",
    "Currently MCP servers are still in it's early development stages and so MCP servers doesn't yet have a direct SSE (Server-Sent Events) connection. To fix this, I have used a package called Supergateway (here: https://github.com/supercorp-ai/supergateway) which establishes a SSE connection for MCP servers. [Note: Currently there are several other ways to connect to MCP servers including downloading MCP servers into your local device and then connecting with the MCP server locally in your device using a Python package called langchain-mcp-tools (here: https://github.com/hideya/langchain-mcp-tools-py, where support for remote MCP server connection is currently experimental) or using the docker approach (here: https://www.youtube.com/watch?v=rdvt1qBZJtI), but I have chosen to use the Supergateway package approach as it is more realistic to connect to remote servers via SSE connections. The Supergateway package is run using npx (which is available in Node.js) which means if you haven't already, you will need to download Node.js (from here: https://nodejs.org/en/download) in order to use the Supergateway package via npx.]\n",
    "\n",
    "Referring to the instructions in the README file in the Supergateway's GitHub repo, in particular the \"stdio â†’ SSE\" section (\"Expose an MCP stdio server as an SSE server:\"):\n",
    "- To establish a SSE connection for the Brave Search MCP Server using Supergateway, run the following command below in your IDE's (for eg. Cursor or VS Code) Terminal window (where this will use port 8001):\n",
    "`npx -y supergateway --stdio \"npx -y @modelcontextprotocol/server-brave-search\" --port 8001 --baseUrl http://localhost:8001 --ssePath /sse --messagePath /message`\n",
    "- To establish a SSE connection for the AccuWeather MCP Server using Supergateway, open a 2nd Terminal window in your IDE and run the following command below in this 2nd Terminal window (where this will use port 8002):\n",
    "`npx -y supergateway --stdio \"uvx --from git+https://github.com/adhikasp/mcp-weather.git mcp-weather\" --port 8002 --baseUrl http://localhost:8002 --ssePath /sse --messagePath /message`\n",
    "\n",
    "**Tip:** If you are unsure how to write the commands above for other MCP servers, just copy and paste the entire README file instructions in Supergateway's GitHub repo and the entire content of the MCP server page in the MCP Server Cloud registry/depository wesbite (for eg. for the Brave Search MCP Server, copy and paste the entire content from this page from the MCP Server Cloud registry/depository website: https://mcpserver.cloud/server/server-brave-search) into an AI and ask the AI to give you the \"stdio â†’ SSE\" command.\n",
    "\n",
    "Now that you have both the Brave Search MCP Server and AccuWeather MCP Server SSE connections running, you can now run the Python script below which uses `http://localhost:8001/sse` for the Brave Search MCP Server and `http://localhost:8002/sse` for the AccuWeather MCP Server.\n",
    "\n",
    "Remember once you are done with using the MCP Servers, you can close off or disconnect the MCP Server's SSE connections by typing \"CTRL\" + \"C\" keys in your IDE's Terminal window.\n",
    "\n",
    "**Takeaway:** This notebook tutorial demonstrates that even without having DeepSeek-R1 fine-tuned for tool calling or even without using my Tool-Ahead-of-Time package (since LangChain's MCP Adapters library works by converting tools in MCP servers into LangChain tools), MCP (via LangChain's MCP Adapters library) still works with DeepSeek-R1. This is likely because DeepSeek-R1 671B is a reasoning model and also how the prompts are written within LangChain's MCP Adapters library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-145' coro=<main() running at C:\\Users\\leo_c\\AppData\\Local\\Temp\\ipykernel_39024\\2469038529.py:23>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the latest AI news highlights from my search:\n",
      "\n",
      "1. **Apple's Health AI Development**  \n",
      "   Apple is reportedly working on an AI-powered health coach called \"AI Doctors\" that could analyze user data from Apple Watch and iPhone to provide personalized health advice. This aligns with their broader health tech ambitions (NYT, PCMag).\n",
      "\n",
      "2. **Google's New AI Model**  \n",
      "   Google released Gemini 2.5 Pro (experimental), now available to free users. This advanced model improves reasoning and multimodal capabilities, expanding access to cutting-edge AI tools (Engadget).\n",
      "\n",
      "3. **Creative AI Tools**  \n",
      "   Free ChatGPT users can now generate Studio Ghibli-style images using DALL-E 3, though this has sparked debate. Prominent animators criticize AI art as \"an insult to life itself\" (Hindustan Times).\n",
      "\n",
      "4. **AI News Reliability**  \n",
      "   The New York Times has corrected dozens of AI-generated news summaries in 2024, highlighting ongoing challenges with accuracy in automated content creation.\n",
      "\n",
      "---\n",
      "\n",
      "**For deeper dives, check these trusted sources:**  \n",
      "- Dedicated AI News: [Artificial Intelligence-News](https://www.artificialintelligence-news.com/)  \n",
      "- Tech Updates: [NBC News AI Section](https://www.nbcnews.com/artificial-intelligence)  \n",
      "- Research Frontiers: [Google AI Blog](https://ai.google/latest-news/)  \n",
      "\n",
      "Would you like details on any specific story? ðŸ¤–\n",
      "Here's the weather forecast for Sydney tomorrow based on the latest information:\n",
      "\n",
      "**Sydney Weather Forecast - Tomorrow:**\n",
      "- **Temperature:** High of 72Â°F (22Â°C), Low of 62Â°F (17Â°C)\n",
      "- **Conditions:** Windy with a mix of clouds and sunshine\n",
      "- **Rain:** 100% chance of rain tonight easing to showers tomorrow\n",
      "- **Wind:** Southwesterly winds at 15-25 mph (24-40 km/h)\n",
      "\n",
      "**Key Details:**\n",
      "1. Morning showers likely, becoming partly cloudy by afternoon.\n",
      "2. Potential rainfall: Up to 0.25 inches (6mm) overnight.\n",
      "3. UV Index: Moderate (sun protection recommended during peak hours).\n",
      "\n",
      "For official updates, check Australia's Bureau of Meteorology: http://www.bom.gov.au/nsw/forecasts/sydney.shtml\n",
      "\n",
      "Would you like clarification on any specific aspect of the forecast?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variable (ie. API key) from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize model\n",
    "model = ChatOpenAI(\n",
    "    model=\"deepseek/deepseek-r1\",\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "# Define the main asynchronous function\n",
    "async def main():\n",
    "    # Configure the MCP clients for Brave Search and Weather servers\n",
    "    async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"brave-search\": {\n",
    "                \"url\": \"http://localhost:8001/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "                \"headers\": {\n",
    "                    \"Authorization\": os.environ[\"BRAVE_API_KEY\"]  # Replace with your Brave Search API key\n",
    "                }\n",
    "            },\n",
    "            \"weather\": {\n",
    "                \"url\": \"http://localhost:8002/sse\",\n",
    "                \"transport\": \"sse\",\n",
    "                \"headers\": {\n",
    "                    \"Authorization\": os.environ[\"ACCUWEATHER_API_KEY\"]  # Replace with your AccuWeather API key\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ) as client:\n",
    "        # Create the agent with access to the tools provided by the MCP servers\n",
    "        agent = create_react_agent(model, client.get_tools())\n",
    "\n",
    "        # Example usage: Perform a web search using Brave Search\n",
    "        search_response = await agent.ainvoke({\n",
    "            \"messages\": \"Search for the latest news on AI.\"\n",
    "        })\n",
    "        print(search_response['messages'][-1].content)\n",
    "\n",
    "        # Example usage: Get the weather forecast using the Weather MCP Server\n",
    "        weather_response = await agent.ainvoke({\n",
    "            \"messages\": \"What's the weather forecast for Sydney tomorrow?\"\n",
    "        })\n",
    "        print(weather_response['messages'][-1].content)\n",
    "\n",
    "# Run the main function using asyncio.ensure_future\n",
    "asyncio.ensure_future(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
